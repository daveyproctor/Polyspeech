---
title: "Politicians' Tweeting Behavior by Gender and Election Success"
output: pdf_document
number_sections: true
author: Davey Proctor
urlcolor: blue
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, results='hide', message=F, warning=F, cache=T, tidy.opts=list(width.cutoff=80),tidy=T)
```

```{r}
# Dependencies
# The usual
library(dplyr)
library(ggplot2)
th <- theme(plot.title = element_text(hjust = 0.5))
ax <- theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(lubridate)
library(reshape2)
library(stringi)
library(tidyr)
# Word cloud
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
# Topic models
library(topicmodels)
library(tidytext)
library(tidyr)
library(tm)
library(textstem)
library(readr)
library(stringr)
# Structured topic models
library(stm)
```

# I. Introduction

We've seen a huge increase in the use of social media; on Twitter an estimated 500 million tweets are sent every day. Politicians use Twitter to mobilize support, attack opponents, share news that endorses their policy, and more. @Stieglitz present a "methodological framework for social media analytics in political context," which includes content analysis, opinion mining, and social network analysis to ask questions such as who are the political opinion leaders and what are the emerging political topics. @Hellweg found that social media use, particularly if personal rather than professional in tone, can significanly enhance the perception followers have of a candidate.

Following @Proctor, who found that strategies in the form of tones of messages in Twitter did not differ by gender, I expand the analysis to ask how different strategies achieve different payoffs come election day. I look for relationships between tweet behavior such as tweet frequency over time, word count, and topic versus election day success. I'm further interesting in aligning these payoffs to metadata characteristics such as gender, party affiliation, age, and polarization level.

# II. Data

## Metadata

```{r}
metaDF <- read.csv("US Politicians Cleaned.csv", as.is = T) %>% 
  mutate(fullname=paste(first_name, last_name)) %>%
  mutate(date_of_birth=ymd_hms(date_of_birth))
colnames(metaDF)
```

The metadata has been aggregated by individuals working in Frances Rosenbluth's lab at Yale. They used sources such as [GovTrack](https://www.govtrack.us/), [Vote Smart](https://votesmart.org/),  and others to determine metadata characteristics of the 115th (2016 election) and 116th (2018 election) members of the U.S. congress (U.S. House and U.S. Senate). Columns include age, party, gender, senator or representative, polarization level via the [dw nominate metric](https://en.wikipedia.org/wiki/NOMINATE_(scaling_method)), and professional action characteristics such as the percentage of time they vote with their party.

## Election data

```{r}
ElectionsDF <- read.csv("US Elections Cleaned.csv", as.is = T)
ElectionsDF <- ElectionsDF %>% filter(year >= 2010) %>%
  mutate(vote_fraction=candidatevotes/totalvotes) %>%
  select(first_name, last_name, state, year, vote_fraction) %>%
  arrange(first_name, last_name, state, year)

nElec <- nrow(metaDF %>% inner_join(ElectionsDF, by=c("first_name", "last_name", "state")))
nInd <- nrow(metaDF %>% inner_join(ElectionsDF, by=c("first_name", "last_name", "state")) %>% count(first_name, last_name, state))
```

For this metadata, I pull in information on their elections from 2010 to 2016 from the [MIT Election Data Science Lab](https://electionlab.mit.edu/data). Over these four elections we have a total of `r nElec` elections from `r nInd` individuals.

```{r}
metaDFWElections <- metaDF %>% select(first_name, last_name, state) %>%
  inner_join(ElectionsDF, by=c("first_name", "last_name", "state"))
spreadVoteFraction <- metaDFWElections %>%
  spread(year, vote_fraction)
colnames(spreadVoteFraction) <- gsub("(201.)", "frac_votes_received_\\1", colnames(spreadVoteFraction))
# library(reshape2)
# spreadVoteFraction %>% melt(id=c("first_name", "last_name", "state")) # How to melt

metaDF <- metaDF %>% left_join(spreadVoteFraction, by=c("first_name", "last_name", "state"))
metaDF
```

## Tweets

```{r}
# New metadata
tweetsMetaDF <- read.csv("pol_accounts.csv", as.is = T, sep=";")
# tweetsMetaDF <- read.csv("https://query.data.world/s/e7375jdc22jydnegcou4hsurtyezsf", as.is=T, sep=";")
tweetsMetaDF <- tweetsMetaDF %>% mutate(created_at=ymd_hms(created_at)) %>%
  mutate(id=as.character(id))
nrow(tweetsMetaDF)
# about 200 in the pol_accounts are not in my metadata, and about 190 are in my metadata but not in pol_accounts.
metaDF <- metaDF %>% inner_join(tweetsMetaDF, by=c("twitter_account"="screen_name")) %>%
  mutate(user_id=id) %>%
  select(-id)
# Easier for unspread elections
UserIDElections <- metaDFWElections %>% inner_join(metaDF %>% select(first_name, last_name, state, user_id)) %>%
  select(user_id, year, vote_fraction)

# Tweets
tweetsDF <- read.csv("pol_tweets.csv", as.is=T, sep=";")
# readRDS("tweetsDF.RDS")
# tweetsDF <- read.csv("https://query.data.world/s/dpgkibmlikucyt4kxchxzdgpriivzf", as.is=T, sep=";");
tweetsDF <- tweetsDF %>% mutate(created_at=ymd_hms(created_at)) %>%
  mutate(id=as.character(id)) %>%
  mutate(user_id=as.character(user_id)) %>%
  arrange(user_id, created_at) %>% 
  select(user_id, created_at, everything())

nTweets <- nrow(tweetsDF %>% select(user_id) %>% inner_join(metaDF %>% select(user_id)))
nIndiv <- nrow(tweetsDF %>% select(user_id) %>% inner_join(metaDF %>% select(user_id)) %>% count(user_id))
firstTweetTime <- tweetsDF[which.min(tweetsDF$created_at),]$created_at
latestTweetTime <- tweetsDF[which.max(tweetsDF$created_at),]$created_at
```

Tweets from this [data.world dataset](https://data.world/bkey/politician-tweets). We have `r nTweets` tweets from `r nIndiv` individuals in our metadata. In addition to the text of the tweet and when it was created (ranging from `r firstTweetTime` to `r latestTweetTime`), they've pulled out hashtag entities, favorite counts, retweets, and urls.

# III. Analysis

# Understanding Recent Elections
In this section I will try to understand election success without looking at tweets. The following plot shows no significant effect of gender on recent election success.

```{r}
metaDF %>% inner_join(ElectionsDF, by=c("first_name", "last_name", "state")) %>% 
  filter(party %in% c("D", "R")) %>%
  ggplot(aes(x=as.factor(year), y=vote_fraction, color=gender)) + geom_boxplot()
```

# Electability vs. Social Media Use
Supplementing the prior section, and the ultimate thrust of the report, here I will analyze different tweeting strategies and ultimately align them with election success.

## Tweet frequency over time

```{r}
metaDFWTweets <- metaDF %>% select(gender, user_id) %>% 
  inner_join(tweetsDF %>% select(created_at, user_id))

# It seems that, while everyone is tweeting more than before, women are perhaps slightly outpacing men recently in tweet frequency, only recently
metaDFWTweets %>%
  group_by(user_id, month=floor_date(created_at, "month")) %>%
  summarise(n=n(), gender=gender[[1]]) %>%
  ggplot(aes(x=month, y=n, color=gender)) + geom_smooth() + ggtitle("Individual's Tweet Counts in Recent Years") + th

# However, tweeting more does not correspond to greater election success for either gender.
metaDF %>% select(user_id, frac_votes_received_2016, gender) %>% 
  inner_join(tweetsDF %>% select(created_at, user_id)) %>%
  filter(created_at>ymd("2014-1-1")) %>%
  group_by(user_id) %>%
  summarise(n=n(), frac_votes_received_2016=frac_votes_received_2016[[1]], gender=gender[[1]]) %>%
  ggplot(aes(x=n, y=frac_votes_received_2016, color=gender)) + geom_smooth() + 
  xlab("Tweets Since 2014") + ggtitle("2016 Election Success vs. Tweet Frequency") + th
```

```{r}
# Women actually availing themselves of Twitter faster than men
m <- lm(n ~ day*gender, data=metaDFWTweets %>% group_by(user_id, day=floor_date(created_at, "day")) %>%
  summarise(n=n(), gender=gender[[1]]))
summary(m)
# summary(aov(m))
```


```{r}
# Compute next election
electionYears <- c(2010, 2012, 2014, 2016)
electionDays <- c(ymd("2010-11-2"), ymd("2012-11-6"), ymd("2014-11-4"), ymd("2016-11-8"))
electionDaysLeadup <- c(ymd("2010-9-2"), ymd("2012-9-6"), ymd("2014-9-4"), ymd("2016-9-8"))
electionIndices <- c(1,2,3,4)
electionDateConversion <- data.frame(electionYears, electionDays, electionDaysLeadup, electionIndices)

tweetsNearElections <- tweetsDF %>% select(id, created_at) %>% 
  filter(created_at < max(electionDays)) %>%
  mutate(nextElectionIs2010_1=(created_at>electionDaysLeadup[1] & created_at<electionDays[1]),
         nextElectionIs2012_2=(created_at>electionDaysLeadup[2] & created_at<electionDays[2]),
         nextElectionIs2014_3=(created_at>electionDaysLeadup[3] & created_at<electionDays[3]),
         nextElectionIs2016_4=(created_at>electionDaysLeadup[4] & created_at<electionDays[4])) %>%
  melt(id=c("id","created_at")) %>%
  filter(value) %>% select(-value) %>%
  mutate(nextElection=as.numeric(gsub(".*201._(.)", "\\1", variable))) %>% select(-variable) %>%
  mutate(nextElectionDate=electionDays[nextElection]) %>% 
  select(id, nextElection, nextElectionDate) %>%
  inner_join(tweetsDF)

table(tweetsNearElections$nextElection)

tweetsNearElections %>% count(user_id, nextElection) %>%
  ggplot(aes(x=n, color=as.factor(nextElection))) + geom_histogram()

#tweetsNearElections %>% group_by(user_id, nextElection) %>%
#  summarise(n=n()) %>%
#  ggplot(aes(x=as.factor(nextElection), y=n)) + geom_boxplot()
```

```{r}
set.seed(123)

tweetsNearElections50 <- tweetsNearElections %>% group_by(user_id, nextElection) %>%
  filter(n()>30) %>%
  filter(row_number() %in% sample(seq(1,n()), min(50, n()))) %>%
  ungroup() 

table(tweetsNearElections$nextElection)
table(tweetsNearElections50$nextElection)

# Most have full 50.
# tweetsNearElections50 %>% count(user_id, nextElection) %>%
#   ggplot(aes(x=n)) + geom_histogram()

tweetsNearElections50 <- tweetsNearElections50 %>% arrange(user_id, created_at) %>% select(id, user_id, created_at, everything())
```

```{r}
# 1039 docs
docsNearElections <- tweetsNearElections50 %>% group_by(user_id, nextElection) %>%
  summarise(doc=stringr::str_c(tweet_text, collapse = " -- ")) %>%
  ungroup() %>%
  mutate(doc_id=as.character(seq(length(doc))))
head(docsNearElections)
# For IBM
# write.csv(docsNearElections %>% select(doc_id, doc), "tweetDocsNearElections.csv", row.names = F)
# write.csv(docsNearElections, "tweetDocsNearElectionsWMeta.csv", row.names = F)
```

```{r}
# Received from IBM
ibmDF <- read.csv("tweetDocsNearElectionsIBM.csv", as.is=T)
ibmDF <- ibmDF %>% mutate(doc_id=as.character(doc_id)) %>%
  group_by(tone_name) %>%
  mutate(standardizedScore=ecdf(score)(score), isHighScore=score>median(score)) %>%
  ungroup()
```

```{r}
# A lot of people are tweeting before elections without actually having an election then. 1039 docs before elections -> 508 actually having an elections (and being in our dataset of elections)
# Also not everyone is in our twitterset. 1128 elections -> 508 with tweets
nrow(UserIDElections)
docsNearElectionsWPayoff <- UserIDElections %>% inner_join(electionDateConversion, by=c("year"="electionYears")) %>%
  select(user_id, electionDays, electionIndices, vote_fraction) %>%
  inner_join(docsNearElections, by=c("user_id", "electionIndices"="nextElection"))
```

```{r}
metaDocsNearElections <- tweetsNearElections50 %>% group_by(user_id, nextElection) %>%
  summarise(fav_all=sum(favorites_count), ret_all=sum(retweet_count)) %>%
  inner_join(docsNearElections, by=c("user_id", "nextElection")) %>%
  inner_join(metaDF %>% select(user_id, first_name, last_name, gender)) %>% # Causes cut bc not all docs are in my metadata
  ungroup()
nrow(metaDocsNearElections)
  
metaDocsNearElectionsWPayoff <- tweetsNearElections50 %>% group_by(user_id, nextElection) %>%
  summarise(fav_all=sum(favorites_count), ret_all=sum(retweet_count)) %>%
             # Uses docs near elect w payoff
  inner_join(docsNearElectionsWPayoff, by=c("user_id", "nextElection"="electionIndices")) %>%
  inner_join(metaDF %>% select(user_id, first_name, last_name, gender)) %>% # No additional cut bc WPayoff required metadata on elections, already had joined w metadata
  ungroup()
nrow(metaDocsNearElectionsWPayoff)
```

```{r}
# slight payoff for being retweeted more before elections
metaDocsNearElectionsWPayoff %>% #filter(ecdf(ret_all)(ret_all)<.80) %>%
  ggplot(aes(x=log(ret_all), y=vote_fraction, color=gender)) + geom_smooth() + geom_point() #+ xlim(3,7.5)
```


```{r}
metaDocsNearElections %>% select(user_id, nextElection, doc_id, fav_all, ret_all, gender) %>%
  inner_join(ibmDF) %>% # 9386 rows
  ggplot(aes(x=tone_name, y=standardizedScore, color=gender)) + geom_boxplot() + ax
```

```{r}
metaDocsNearElections %>% inner_join(ibmDF) %>% 
  filter(tone_name %in% sort(unique(ibmDF$tone_name))[8:13]) %>%
  ggplot(aes(x=tone_name, y=log(ret_all), color=gender, fill=isHighScore)) + geom_boxplot() + ax + scale_color_manual(values=c("black", "white"))

metaDocsNearElections %>% inner_join(ibmDF) %>% 
  filter(tone_name %in% sort(unique(ibmDF$tone_name))[1:7]) %>%
  ggplot(aes(x=tone_name, y=log(ret_all), color=gender, fill=isHighScore)) + geom_boxplot() + ax + scale_color_manual(values=c("black", "white"))
```

* We see men get helped if they are open, women helped if NOT open.

```{r}
metaDocsNearElections %>% inner_join(ibmDF) %>%
  filter(tone_name=="Openness") %>%
  ggplot(aes(x=gender, y=log(ret_all), fill=isHighScore)) + geom_boxplot()
metaDocsNearElections %>% inner_join(ibmDF) %>%
  filter(tone_name=="Confident") %>%
  ggplot(aes(x=gender, y=log(ret_all), fill=isHighScore)) + geom_boxplot()
metaDocsNearElections %>% inner_join(ibmDF) %>%
  filter(tone_name=="Fear") %>%
  ggplot(aes(x=gender, y=log(ret_all), fill=isHighScore)) + geom_boxplot()
metaDocsNearElections %>% inner_join(ibmDF) %>%
  filter(tone_name=="Joy") %>%
  ggplot(aes(x=gender, y=log(ret_all), fill=isHighScore)) + geom_boxplot()
```

```{r}
summary(lm(log(ret_all)~gender*isHighScore*tone_name, data=metaDocsNearElections %>% inner_join(ibmDF)))
# summary(lm(log(ret_all)~gender*isHighScore, data=metaDocsNearElections %>% inner_join(ibmDF) %>%
#   filter(tone_name=="Fear"))) # *
# summary(lm(log(ret_all)~gender*isHighScore, data=metaDocsNearElections %>% inner_join(ibmDF) %>%
#   filter(tone_name=="Joy"))) # *
# summary(lm(log(ret_all)~gender*isHighScore, data=metaDocsNearElections %>% inner_join(ibmDF) %>%
#   filter(tone_name=="Confident"))) # *
```

```{r}
# Overall, no effect. good.
# metaDocsNearElectionsWPayoff %>% select(doc_id, gender, vote_fraction) %>%
#   inner_join(ibmDF) %>%
#   ggplot(aes(x=standardizedScore, y=vote_fraction)) + geom_smooth() + geom_point()

# Nothing for openness.
# Women maybe hurt a little for tentative
# metaDocsNearElectionsWPayoff %>% select(doc_id, gender, vote_fraction) %>%
#   inner_join(ibmDF) %>%
#   filter(tone_name=="Tentative") %>%
#   ggplot(aes(x=standardizedScore, y=vote_fraction, color=gender)) + geom_smooth()

# Women helpfed for Fear, just like retweet more
metaDocsNearElectionsWPayoff %>% select(doc_id, gender, vote_fraction) %>%
  inner_join(ibmDF) %>%
  filter(tone_name=="Fear") %>%
  ggplot(aes(x=standardizedScore, y=vote_fraction, color=gender)) + geom_smooth()

# Also helped for disgust
metaDocsNearElectionsWPayoff %>% select(doc_id, gender, vote_fraction) %>%
  inner_join(ibmDF) %>%
  filter(tone_name=="Disgust") %>%
  ggplot(aes(x=standardizedScore, y=vote_fraction, color=gender)) + geom_smooth()

# Both hurt for joy
metaDocsNearElectionsWPayoff %>% select(doc_id, gender, vote_fraction) %>%
  inner_join(ibmDF) %>%
  filter(tone_name=="Joy") %>%
  ggplot(aes(x=standardizedScore, y=vote_fraction, color=gender)) + geom_smooth()

# A little for Anger, confident helps if SUPER confident
metaDocsNearElectionsWPayoff %>% select(doc_id, gender, vote_fraction) %>%
  inner_join(ibmDF) %>%
  filter(tone_name=="Confident") %>%
  ggplot(aes(x=standardizedScore, y=vote_fraction, color=gender)) + geom_smooth()
```

```{r}
summary(lm(vote_fraction~standardizedScore*tone_name*gender, data=metaDocsNearElectionsWPayoff %>% select(doc_id, gender, vote_fraction) %>%
  inner_join(ibmDF)))
```


## Tweet Hashtags
Hashtags are a way for users to self-identify topics that relate to their tweets, so it's a good place to start when doing any content analysis.

### Word frequencies
The simplest analysis just looks at freqencies of hashtags.
<!-- This is a frequency chart of hashtag entities of all our politicians: -->

```{r, fig.show = 'hide'}
hashtags_per_user <- tweetsDF %>% select(user_id, hashtag_entities, created_at) %>%
  mutate(hashtag_entities=gsub(",", " ", gsub("\\{(.*)\\}", "\\1", hashtag_entities), ","))  %>%
  unnest_tokens(hashtag, hashtag_entities)
# annoying id field drop
# hashtags_per_user <- data.frame(user_id=hashtags_per_user$user_id, hashtag=hashtags_per_user$hashtag, date=hashtags_per_user$ stringsAsFactors = F)
x <- hashtags_per_user %>% count(hashtag)
set.seed(1234)
wordcloud(words = x$hashtag, freq = x$n, min.freq = 500,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

Connects with plot of big spike we saw in the tweet frequency chart

```{r}
metaDFWTweets %>%
  group_by(user_id, month=floor_date(created_at, "month")) %>%
  summarise(n=n(), gender=gender[[1]]) %>%
  ggplot(aes(x=month, y=n, color=gender)) + geom_smooth()
```

```{r}
# How much is Obamacare alone causing it?
hashtags_per_user %>%
  group_by(month=floor_date(created_at, "month")) %>%
  summarise(Obamacount=length(which(hashtag=="obamacare"))) %>%
  ggplot(aes(x=month, y=Obamacount)) + geom_point() #+ geom_smooth()
```

```{r}
rev(sort(table(hashtags_per_user$hashtag)))[1:10]
```


```{r}
x <- hashtags_per_user %>% filter(created_at>ymd("2012-01-01") & created_at<ymd("2014-01-01")) %>% count(hashtag)
set.seed(1234)
wordcloud(words = x$hashtag, freq = x$n, min.freq = 500,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

This is a word cloud of hashtag entities of female politicians:

```{r}
x <- hashtags_per_user %>% inner_join(metaDF, by=c("user_id")) %>%
  count(gender, hashtag)
w <- x %>% filter(gender=="F")
m <- x %>% filter(gender=="M")
set.seed(1234)
wordcloud(words = w$hashtag, freq = w$n, min.freq = 500,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

We can compare with the men's hashtags:

```{r}
wordcloud(words = m$hashtag, freq = m$n, min.freq = 500,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

Comparing between the two, there are clear "women's" topics that appear among the women, such as BringBackOurGirls, Zika, and EqualPay that weren't among the men.

## Topic models

I will run topic models on on the tweets directly, but to start I just focused on the hashtags.

```{r}
x <- hashtags_per_user %>% count(user_id, hashtag) %>%
  cast_dtm(user_id, hashtag, n)
x %>% tidy() %>% arrange(document)
```

Running directly on tweets:

```{r}
# https://piazza.com/class/jl26r45x64v60r?cid=251
stack <- metaDocsNearElectionsWPayoff %>% select(doc_id, doc) %>% # rename columns
  unnest_tokens(output = word, 
                input = doc,
                to_lower = TRUE,
                drop = TRUE,
                strip_punct = TRUE,
                strip_numeric = TRUE) %>% # tokenizes
  anti_join(stop_words, by = "word") %>% # removes stopwords (for example, removes 'what', 'is', and 'about')
  mutate(word = lemmatize_words(word)) %>% # lemmatizes words (for example, combines 'test', 'tests', and 'testing'
  group_by(doc_id, word) %>%
  summarize(n = n()) # count word frequency per word per document

wordFreq <- stack %>%
  group_by(word) %>%
  summarize(n = n())

vocabulary <- wordFreq %>%
  filter(n >= 20) %>%
  filter(!str_detect(word, "\\d")) %>% # keep words that have no digits
  filter(!str_detect(word, "\\.")) %>% # keep words that have no periods
  filter(!(word %in% c("https", "http", "rt", "amp")))
  # add additional statements here to trim vocabulary

stackTrimmed <- semi_join(stack, vocabulary, by = "word")
# the semi-join takes the stack dataframe and remove all rows where the value of the "word" column cannot be found in the vocabulary dataframe's "word" column

stackTrimmed

stackDTM <- cast_dtm(stackTrimmed, term = word, document = doc_id, value = n)
```

```{r}
hash_lda <- LDA(stackDTM, k=6, control = list(seed = 1234))

# Hashtags
# hash_lda <- LDA(x, k=6, control = list(seed = 1234))
```

The most common words in a six-topic model are shown:

```{r}
hash_topics <- tidy(hash_lda, matrix = "beta")
hash_topics

hash_top_terms <- hash_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

hash_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

Breaking this down by gender, we find that women are tweeting more on the second topic.

```{r}
hash_documents <- tidy(hash_lda, matrix = "gamma")
hash_documents %>% arrange(document, topic)
hash_documents %>% inner_join(metaDocsNearElectionsWPayoff %>% select(doc_id, gender), by=c("document"="doc_id")) %>%
# hashtags
#hash_documents %>% inner_join(metaDF %>% select(user_id, gender), by=c("document"="user_id")) %>%
  group_by(topic, gender) %>%
  summarise(meanGam=mean(gamma)) %>%
  ggplot(aes(x=as.factor(topic), y=meanGam, color=gender)) + geom_point()
```

# Still Todo:
Include more metadata characteristics in the structured topic models, including election success. See if there is some interpretable interaction between tweeting about certain topics and success in the elections. Think about documents over time, and model changes in topics over time.

# References

<!-- # Appendix -->
<!-- ## Detials: Code -->
<!-- ```{r ref.label=knitr::all_labels(), echo=T, eval=F} -->

<!-- ``` -->



