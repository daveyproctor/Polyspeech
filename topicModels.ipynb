{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/susanli2016/Machine-Learning-with-Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from progress import ProgressTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/daveyproctor/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs dog dog\n",
      "ran run ran\n",
      "discouraged discourage discouraged\n"
     ]
    }
   ],
   "source": [
    "for w in ['dogs', 'ran', 'discouraged']:\n",
    "    print(w, get_lemma(w), get_lemma2(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/daveyproctor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "text_data = []\n",
    "with open('data/dataset.csv') as f:\n",
    "    for line in f:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        if random.random() > .99:\n",
    "            print(tokens)\n",
    "            text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTweets = 4000000\n",
    "tracker = ProgressTracker(maxTweets)\n",
    "full_texts = []\n",
    "twitter_accounts = []\n",
    "with open('data/tweetsDFMin.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row, line_count in zip(csv_reader, range(maxTweets)):\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "        else:\n",
    "            try:\n",
    "                full_texts.append(row[1])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            try:\n",
    "                twitter_accounts.append(row[2])\n",
    "            except IndexError:\n",
    "                full_texts.pop()\n",
    "                pass\n",
    "        tracker.update(line_count)\n",
    "    print(f'Processed {line_count} lines.')\n",
    "    print(f'Got {len(full_texts)} tweets')\n",
    "    print(f'Got {len(twitter_accounts)} account ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF = pd.DataFrame({\"full_text\": full_texts, \"twitter_account\": twitter_accounts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF.to_csv(\"data/tweetsDFMinReadable.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF = pd.read_csv(\"data/tweetsDFMinReadable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTweets = None\n",
    "rawTweets = tweetsDF.loc[:maxTweets,\"full_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or, choosing to treat tweet sets as documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTweets = tweetsDF.groupby('twitter_account')['full_text'].apply(lambda x: \"%s\" % ' --\\n '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preppedTweets = [prepare_text_for_lda(text) for text in rawTweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCREEN_NAME',\n",
       " '1)some',\n",
       " 'thought',\n",
       " 'value',\n",
       " 'reading',\n",
       " 'fiction',\n",
       " 'early',\n",
       " 'book',\n",
       " 'mostly']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = rawTweets[0]\n",
    "import json\n",
    "json.loads(json.dumps(prepare_text_for_lda(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF.loc[0, \"tweet_word_roots\"] = json.dumps(prepare_text_for_lda(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slightly faster if you initialize column first, not much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF[\"tweet_word_roots\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 percent done. i: 29334. Time Elapsed: 30.657868146896362\n",
      "2 percent done. i: 58668. Time Elapsed: 61.07813882827759\n",
      "3 percent done. i: 88002. Time Elapsed: 93.2192280292511\n",
      "4 percent done. i: 117336. Time Elapsed: 119.55691194534302\n",
      "5 percent done. i: 146670. Time Elapsed: 148.64076280593872\n",
      "6 percent done. i: 176004. Time Elapsed: 181.2862069606781\n",
      "7 percent done. i: 205338. Time Elapsed: 208.6675248146057\n",
      "8 percent done. i: 234672. Time Elapsed: 237.32731199264526\n",
      "9 percent done. i: 264006. Time Elapsed: 269.7783181667328\n",
      "10 percent done. i: 293340. Time Elapsed: 297.81162190437317\n",
      "11 percent done. i: 322674. Time Elapsed: 328.09203696250916\n",
      "12 percent done. i: 352007. Time Elapsed: 361.8807260990143\n",
      "13 percent done. i: 381341. Time Elapsed: 394.57716608047485\n",
      "14 percent done. i: 410675. Time Elapsed: 425.6127791404724\n",
      "15 percent done. i: 440009. Time Elapsed: 456.46178698539734\n",
      "16 percent done. i: 469343. Time Elapsed: 488.3932740688324\n",
      "17 percent done. i: 498677. Time Elapsed: 522.487879037857\n",
      "18 percent done. i: 528011. Time Elapsed: 554.387326002121\n",
      "19 percent done. i: 557345. Time Elapsed: 584.7173290252686\n",
      "20 percent done. i: 586679. Time Elapsed: 614.2805209159851\n",
      "21 percent done. i: 616013. Time Elapsed: 646.0789382457733\n",
      "22 percent done. i: 645347. Time Elapsed: 678.8659379482269\n",
      "23 percent done. i: 674680. Time Elapsed: 711.3383119106293\n",
      "24 percent done. i: 704014. Time Elapsed: 742.2051258087158\n",
      "25 percent done. i: 733348. Time Elapsed: 769.8636858463287\n",
      "26 percent done. i: 762682. Time Elapsed: 803.0113401412964\n",
      "27 percent done. i: 792016. Time Elapsed: 837.9700238704681\n",
      "28 percent done. i: 821350. Time Elapsed: 869.5646710395813\n",
      "29 percent done. i: 850684. Time Elapsed: 901.8546559810638\n",
      "30 percent done. i: 880018. Time Elapsed: 935.2069959640503\n",
      "31 percent done. i: 909352. Time Elapsed: 968.3742232322693\n",
      "32 percent done. i: 938686. Time Elapsed: 1002.2350609302521\n",
      "33 percent done. i: 968020. Time Elapsed: 1035.3032851219177\n",
      "34 percent done. i: 997353. Time Elapsed: 1068.5823621749878\n",
      "35 percent done. i: 1026687. Time Elapsed: 1100.9881868362427\n",
      "36 percent done. i: 1056021. Time Elapsed: 1132.453115940094\n",
      "37 percent done. i: 1085355. Time Elapsed: 1165.6647639274597\n",
      "38 percent done. i: 1114689. Time Elapsed: 1201.849385023117\n",
      "39 percent done. i: 1144023. Time Elapsed: 1236.179020166397\n",
      "40 percent done. i: 1173357. Time Elapsed: 1268.9058649539948\n",
      "41 percent done. i: 1202691. Time Elapsed: 1303.5920708179474\n",
      "42 percent done. i: 1232025. Time Elapsed: 1339.1345310211182\n",
      "43 percent done. i: 1261359. Time Elapsed: 1373.5925650596619\n",
      "44 percent done. i: 1290693. Time Elapsed: 1406.612645149231\n",
      "45 percent done. i: 1320026. Time Elapsed: 1439.5971789360046\n",
      "46 percent done. i: 1349360. Time Elapsed: 1473.8577349185944\n",
      "47 percent done. i: 1378694. Time Elapsed: 1505.6443500518799\n",
      "48 percent done. i: 1408028. Time Elapsed: 1541.3690948486328\n",
      "49 percent done. i: 1437362. Time Elapsed: 1576.7249448299408\n",
      "50 percent done. i: 1466696. Time Elapsed: 1613.4500150680542\n",
      "51 percent done. i: 1496030. Time Elapsed: 1650.7846038341522\n",
      "52 percent done. i: 1525364. Time Elapsed: 1684.968859910965\n",
      "53 percent done. i: 1554698. Time Elapsed: 1722.935033082962\n",
      "54 percent done. i: 1584032. Time Elapsed: 1760.0590860843658\n",
      "55 percent done. i: 1613366. Time Elapsed: 1795.0835409164429\n",
      "56 percent done. i: 1642699. Time Elapsed: 1837.5584909915924\n",
      "57 percent done. i: 1672033. Time Elapsed: 1879.3585600852966\n",
      "58 percent done. i: 1701367. Time Elapsed: 1917.4082770347595\n",
      "59 percent done. i: 1730701. Time Elapsed: 1956.2625448703766\n",
      "60 percent done. i: 1760035. Time Elapsed: 2001.9268779754639\n",
      "61 percent done. i: 1789369. Time Elapsed: 2045.718633890152\n",
      "62 percent done. i: 1818703. Time Elapsed: 2085.954337120056\n",
      "63 percent done. i: 1848037. Time Elapsed: 2126.241294145584\n",
      "64 percent done. i: 1877371. Time Elapsed: 2165.0596470832825\n",
      "65 percent done. i: 1906705. Time Elapsed: 2198.8590309619904\n",
      "66 percent done. i: 1936039. Time Elapsed: 2230.8666501045227\n",
      "67 percent done. i: 1965372. Time Elapsed: 2266.8407900333405\n",
      "68 percent done. i: 1994706. Time Elapsed: 2301.9675149917603\n",
      "69 percent done. i: 2024040. Time Elapsed: 2334.4253509044647\n",
      "70 percent done. i: 2053374. Time Elapsed: 2368.721778869629\n",
      "71 percent done. i: 2082708. Time Elapsed: 2400.367388010025\n",
      "72 percent done. i: 2112042. Time Elapsed: 2431.4526069164276\n",
      "73 percent done. i: 2141376. Time Elapsed: 2462.634105205536\n",
      "74 percent done. i: 2170710. Time Elapsed: 2494.404027938843\n",
      "75 percent done. i: 2200044. Time Elapsed: 2530.2338399887085\n",
      "76 percent done. i: 2229378. Time Elapsed: 2559.8191180229187\n",
      "77 percent done. i: 2258712. Time Elapsed: 2593.446387052536\n",
      "78 percent done. i: 2288045. Time Elapsed: 2629.3227660655975\n",
      "79 percent done. i: 2317379. Time Elapsed: 2659.065661907196\n",
      "80 percent done. i: 2346713. Time Elapsed: 2692.1332421302795\n",
      "81 percent done. i: 2376047. Time Elapsed: 2736.9450781345367\n",
      "82 percent done. i: 2405381. Time Elapsed: 2770.555976867676\n",
      "83 percent done. i: 2434715. Time Elapsed: 2808.1241459846497\n",
      "84 percent done. i: 2464049. Time Elapsed: 2863.04989695549\n",
      "85 percent done. i: 2493383. Time Elapsed: 2895.4323031902313\n",
      "86 percent done. i: 2522717. Time Elapsed: 2930.5660240650177\n",
      "87 percent done. i: 2552051. Time Elapsed: 2967.420161962509\n",
      "88 percent done. i: 2581385. Time Elapsed: 3001.1977989673615\n",
      "89 percent done. i: 2610718. Time Elapsed: 3035.663253068924\n",
      "90 percent done. i: 2640052. Time Elapsed: 3072.0556919574738\n",
      "91 percent done. i: 2669386. Time Elapsed: 3106.1864361763\n",
      "92 percent done. i: 2698720. Time Elapsed: 3137.074563026428\n",
      "93 percent done. i: 2728054. Time Elapsed: 3169.1863009929657\n",
      "94 percent done. i: 2757388. Time Elapsed: 3201.353956222534\n",
      "95 percent done. i: 2786722. Time Elapsed: 3234.078376054764\n",
      "96 percent done. i: 2816056. Time Elapsed: 3269.3059480190277\n",
      "97 percent done. i: 2845390. Time Elapsed: 3303.448728084564\n",
      "98 percent done. i: 2874724. Time Elapsed: 3333.574336051941\n",
      "99 percent done. i: 2904058. Time Elapsed: 3367.2092139720917\n"
     ]
    }
   ],
   "source": [
    "tracker = ProgressTracker(len(rawTweets), 1)\n",
    "preppedTweets = []\n",
    "for i, text in enumerate(rawTweets):\n",
    "    preppedTweets.append(prepare_text_for_lda(text))\n",
    "    tracker.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(preppedTweets, open(\"data/LDApreprocessedTweets.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preppedTweets1 = pickle.load(open(\"data/LDApreprocessedTweets.pkl\", \"rb\"))\n",
    "preppedTweets == preppedTweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF[\"preppedTweets\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = [json.dumps(preppedTweets[i]) if i < len(preppedTweets) else np.nan for i in range(len(tweetsDF))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF[\"preppedTweets\"] = jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCREEN_NAME',\n",
       " '1)some',\n",
       " 'thought',\n",
       " 'value',\n",
       " 'reading',\n",
       " 'fiction',\n",
       " 'early',\n",
       " 'book',\n",
       " 'mostly']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(tweetsDF.loc[0,\"preppedTweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF.to_csv(\"data/tweetsDFMinReadableLDApreprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF = pd.read_csv(\"data/tweetsDFMinReadableLDApreprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get groups in a good spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-f31cc4162667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "sum(preppedTweets[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_account</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuntingtonMayor</td>\n",
       "      <td>RT @medcouragement: Great Ted Talk by one of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ianpgary</td>\n",
       "      <td>RT @NikoLusiani: What an opening salvo in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IlhanMN</td>\n",
       "      <td>We are literally watching a manufactured crisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InhofePress</td>\n",
       "      <td>RT @tulsaworld: Sen. @JimInhofe defends milita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAHimes</td>\n",
       "      <td>@dyanna27 @RepJohnLarson @RepJoeCourtney @rosa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JMVivancoHRW</td>\n",
       "      <td>El influyente congresista @RepMcGovern dice qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JPenaMelnyk</td>\n",
       "      <td>So honored to receive this award with @CherylK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JRClemmons</td>\n",
       "      <td>I proudly joined the @TNJusticeCenter &amp;amp; #h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JacksonLeeTX18</td>\n",
       "      <td>This is wonderful news.  I am pleased that #ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JacksonforIndy</td>\n",
       "      <td>#Composure #GodsGrace https://t.co/CnwJUZfpWs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JakeCorman</td>\n",
       "      <td>HAPPENING NOW: The 103rd #PAFarmShow runs thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JanSchakowsky</td>\n",
       "      <td>RT @CNN: JUST IN: House Speaker Nancy Pelosi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JaneLubchenco</td>\n",
       "      <td>RT @tonybarnosky: Great postdoc in #Anthropoce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JanetKavandi</td>\n",
       "      <td>RT @JimBridenstine: 50 years ago this Christma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JaredPolis</td>\n",
       "      <td>An inside look at the transition:\\nhttps://t.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JasonInTheHouse</td>\n",
       "      <td>RT @ProvoPolice: Funeral services for Officer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JasonPerillo</td>\n",
       "      <td>Pleased to support Shelton's Atty Welch to a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JeffFlake</td>\n",
       "      <td>Looking forward to speaking at the Chancellor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>JeffFortenberry</td>\n",
       "      <td>Every two years in America, we experience some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>JerryMoran</td>\n",
       "      <td>RT @USNavy: THIS WEEK: #USSWichita joins #USNa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>JimLangevin</td>\n",
       "      <td>Americans shouldn’t have to wait for their tax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JimMarston</td>\n",
       "      <td>RT @WndSlrAlliance: Wind and solar energy save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JimPressOffice</td>\n",
       "      <td>RT @BadgerFootball: Joe Thomas in one emoji: 🐐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Jim_Jordan</td>\n",
       "      <td>\"Democrats are focused on stopping the Preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JoaquinCastrotx</td>\n",
       "      <td>RT @Thegrateandrini: @JoaquinCastrotx @POTUS W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JoeBolkcom</td>\n",
       "      <td>RT @troymprice: Thank you to the @iowademocrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JohnBoozman</td>\n",
       "      <td>RT @BarryMoehring: Honored to have had Senator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>JohnCornyn</td>\n",
       "      <td>American disengagement from the world stage of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>JohnLegere</td>\n",
       "      <td>@JesseCale Easy - we aren't @ATT or @Verizon a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>JohnSharpeJames</td>\n",
       "      <td>Cops looking for hit-and-run driver who left 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>vote4craigfaith</td>\n",
       "      <td>RT @LSPDPIO: The 25th annual Holly Festival Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>votepatsykinsey</td>\n",
       "      <td>“It is foolish and wrong to mourn the men who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>votepittman</td>\n",
       "      <td>@RuiXuKS Not allowed on the floor but they can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>voteplata</td>\n",
       "      <td>Don't miss the opportunity to cast your vote d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>votesgilmore</td>\n",
       "      <td>Please join us! #community #district11\\nhttps:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>votetonya</td>\n",
       "      <td>Congrats @AlleganTechCntr on opening the new a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>votetrevordrown</td>\n",
       "      <td>RT @pilkingtonforar: Thank you @G_Stubblefield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>votezimmerman</td>\n",
       "      <td>Cold temperatures snd Santa Claus...it must be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>wakeshoperis</td>\n",
       "      <td>@Zuku_WeCare the below is what I am seeing in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>wandaforala2019</td>\n",
       "      <td>Thank you Joint Conference of Librarians of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ward2bev</td>\n",
       "      <td>Nice work Stop n Shop!  Plastic bag free start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>warrengraeff</td>\n",
       "      <td>@22Chloe_Lynae @DodsonJace A high school class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>wasserman_p</td>\n",
       "      <td>But, the censors struck out any direct mention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>wendyfranzen</td>\n",
       "      <td>Crispy Shaved Brussels Sprouts with Calabrian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>wendygooditis</td>\n",
       "      <td>RT @QuinnipiacPoll: Dems Hold Double-Digit Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>wenschmidt</td>\n",
       "      <td>RT @darinlayman: Awesome! https://t.co/58aXFgA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>willarhh</td>\n",
       "      <td>⚡️ \"President Obama is a feminist\"\\n\\nhttps://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>winniebrinksmi</td>\n",
       "      <td>So excited to serve with this Grand Rapids Pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>wittenberg4rep</td>\n",
       "      <td>RT @ChrisMurphyCT: 97% of Americans believe th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>wjm227</td>\n",
       "      <td>RT @BenedettisDeli: So excited to be on The Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>wmrodgersiii</td>\n",
       "      <td>RT @WSpriggs: @WMRodgersIII presenting on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>wping</td>\n",
       "      <td>Long time coming and cannot wait! Huge thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>wyomingwinters</td>\n",
       "      <td>@EdBuchananWyo You guys are doing great! --\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>yessamjc</td>\n",
       "      <td>RT @RecruitingMHP: Just a reminder!  The deadl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>yianchen24</td>\n",
       "      <td>#sorrybutnotsorry La La Land https://t.co/29uR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>yokabrandt</td>\n",
       "      <td>#Proud to have worked for more than 4 years fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>ypmamigo</td>\n",
       "      <td>@Ryanair There is another strike of on 25-26 J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>yrmcsafety</td>\n",
       "      <td>ADHS Partners Meeting in PHX. Hearing great up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>yujin_1</td>\n",
       "      <td>sdfhsfghnrjurtdhohjxcrh https://t.co/7OpTC5oSq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>zhicks</td>\n",
       "      <td>https://t.co/xXCwPVubst. Thank you AIS for thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     twitter_account                                          full_text\n",
       "0    HuntingtonMayor  RT @medcouragement: Great Ted Talk by one of m...\n",
       "1           Ianpgary  RT @NikoLusiani: What an opening salvo in the ...\n",
       "2            IlhanMN  We are literally watching a manufactured crisi...\n",
       "3        InhofePress  RT @tulsaworld: Sen. @JimInhofe defends milita...\n",
       "4            JAHimes  @dyanna27 @RepJohnLarson @RepJoeCourtney @rosa...\n",
       "5       JMVivancoHRW  El influyente congresista @RepMcGovern dice qu...\n",
       "6        JPenaMelnyk  So honored to receive this award with @CherylK...\n",
       "7         JRClemmons  I proudly joined the @TNJusticeCenter &amp; #h...\n",
       "8     JacksonLeeTX18  This is wonderful news.  I am pleased that #ju...\n",
       "9     JacksonforIndy  #Composure #GodsGrace https://t.co/CnwJUZfpWs ...\n",
       "10        JakeCorman  HAPPENING NOW: The 103rd #PAFarmShow runs thro...\n",
       "11     JanSchakowsky  RT @CNN: JUST IN: House Speaker Nancy Pelosi a...\n",
       "12     JaneLubchenco  RT @tonybarnosky: Great postdoc in #Anthropoce...\n",
       "13      JanetKavandi  RT @JimBridenstine: 50 years ago this Christma...\n",
       "14        JaredPolis  An inside look at the transition:\\nhttps://t.c...\n",
       "15   JasonInTheHouse  RT @ProvoPolice: Funeral services for Officer ...\n",
       "16      JasonPerillo  Pleased to support Shelton's Atty Welch to a s...\n",
       "17         JeffFlake  Looking forward to speaking at the Chancellor'...\n",
       "18   JeffFortenberry  Every two years in America, we experience some...\n",
       "19        JerryMoran  RT @USNavy: THIS WEEK: #USSWichita joins #USNa...\n",
       "20       JimLangevin  Americans shouldn’t have to wait for their tax...\n",
       "21        JimMarston  RT @WndSlrAlliance: Wind and solar energy save...\n",
       "22    JimPressOffice  RT @BadgerFootball: Joe Thomas in one emoji: 🐐...\n",
       "23        Jim_Jordan  \"Democrats are focused on stopping the Preside...\n",
       "24   JoaquinCastrotx  RT @Thegrateandrini: @JoaquinCastrotx @POTUS W...\n",
       "25        JoeBolkcom  RT @troymprice: Thank you to the @iowademocrat...\n",
       "26       JohnBoozman  RT @BarryMoehring: Honored to have had Senator...\n",
       "27        JohnCornyn  American disengagement from the world stage of...\n",
       "28        JohnLegere  @JesseCale Easy - we aren't @ATT or @Verizon a...\n",
       "29   JohnSharpeJames  Cops looking for hit-and-run driver who left 2...\n",
       "..               ...                                                ...\n",
       "228  vote4craigfaith  RT @LSPDPIO: The 25th annual Holly Festival Cr...\n",
       "229  votepatsykinsey  “It is foolish and wrong to mourn the men who ...\n",
       "230      votepittman  @RuiXuKS Not allowed on the floor but they can...\n",
       "231        voteplata  Don't miss the opportunity to cast your vote d...\n",
       "232     votesgilmore  Please join us! #community #district11\\nhttps:...\n",
       "233        votetonya  Congrats @AlleganTechCntr on opening the new a...\n",
       "234  votetrevordrown  RT @pilkingtonforar: Thank you @G_Stubblefield...\n",
       "235    votezimmerman  Cold temperatures snd Santa Claus...it must be...\n",
       "236     wakeshoperis  @Zuku_WeCare the below is what I am seeing in ...\n",
       "237  wandaforala2019  Thank you Joint Conference of Librarians of Co...\n",
       "238         ward2bev  Nice work Stop n Shop!  Plastic bag free start...\n",
       "239     warrengraeff  @22Chloe_Lynae @DodsonJace A high school class...\n",
       "240      wasserman_p  But, the censors struck out any direct mention...\n",
       "241     wendyfranzen  Crispy Shaved Brussels Sprouts with Calabrian ...\n",
       "242    wendygooditis  RT @QuinnipiacPoll: Dems Hold Double-Digit Lea...\n",
       "243       wenschmidt  RT @darinlayman: Awesome! https://t.co/58aXFgA...\n",
       "244         willarhh  ⚡️ \"President Obama is a feminist\"\\n\\nhttps://...\n",
       "245   winniebrinksmi  So excited to serve with this Grand Rapids Pub...\n",
       "246   wittenberg4rep  RT @ChrisMurphyCT: 97% of Americans believe th...\n",
       "247           wjm227  RT @BenedettisDeli: So excited to be on The Be...\n",
       "248     wmrodgersiii  RT @WSpriggs: @WMRodgersIII presenting on the ...\n",
       "249            wping  Long time coming and cannot wait! Huge thanks ...\n",
       "250   wyomingwinters  @EdBuchananWyo You guys are doing great! --\\n ...\n",
       "251         yessamjc  RT @RecruitingMHP: Just a reminder!  The deadl...\n",
       "252       yianchen24  #sorrybutnotsorry La La Land https://t.co/29uR...\n",
       "253       yokabrandt  #Proud to have worked for more than 4 years fo...\n",
       "254         ypmamigo  @Ryanair There is another strike of on 25-26 J...\n",
       "255       yrmcsafety  ADHS Partners Meeting in PHX. Hearing great up...\n",
       "256          yujin_1  sdfhsfghnrjurtdhohjxcrh https://t.co/7OpTC5oSq...\n",
       "257           zhicks  https://t.co/xXCwPVubst. Thank you AIS for thi...\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxTweets = 500000\n",
    "tweetsDF[:maxTweets].groupby('twitter_account')['full_text'].apply(lambda x: \"%s\" % ' --\\n '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"SCREEN_NAME\", \"1)some\", \"thought\", \"value\", \"reading\", \"fiction\", \"early\", \"book\", \"mostly\"]'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF.preppedTweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['full_text', 'twitter_account', 'preppedTweets'], dtype='object')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ProgressTracker(2065, 5)\n",
    "def decodeFlatten(df):\n",
    "    print(df.columns)\n",
    "    jsonlsts = df.preppedTweets\n",
    "    print(jsonlsts[0])\n",
    "    print(df.preppedTweets[0])\n",
    "    raise RuntimeError\n",
    "    tracker.update()\n",
    "#     print(jsonlsts)\n",
    "    lsts = [json.loads(arr) for arr in jsonlsts] \n",
    "    flatlst = []\n",
    "    for lst in lsts:\n",
    "        for item in lst:\n",
    "            flatlst.append(item)\n",
    "#     print(\"flatlist\", flatlst)\n",
    "    return json.dumps(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['full_text', 'twitter_account', 'preppedTweets'], dtype='object')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_fast\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    609\u001b[0m                                           dummy)\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.SeriesGrouper.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.SeriesGrouper.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_builtin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-574c424dcd1e>\u001b[0m in \u001b[0;36mdecodeFlatten\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecodeFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mjsonlsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_pure_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_builtin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-574c424dcd1e>\u001b[0m in \u001b[0;36mdecodeFlatten\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecodeFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mjsonlsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m                     result = self._aggregate_multiple_funcs(\n\u001b[0;32m--> 201\u001b[0;31m                         [arg], _level=_level, _axis=self.axis)\n\u001b[0m\u001b[1;32m    202\u001b[0m                     result.columns = Index(\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[0;34m(self, arg, _level, _axis)\u001b[0m\n\u001b[1;32m    604\u001b[0m                                          subset=obj.iloc[:, index])\n\u001b[0;32m--> 605\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m             ret = self._aggregate_multiple_funcs(func_or_funcs,\n\u001b[0;32m--> 766\u001b[0;31m                                                  (_level or 0) + 1)\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[0;34m(self, arg, _level)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_named\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_named\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-574c424dcd1e>\u001b[0m in \u001b[0;36mdecodeFlatten\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecodeFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mjsonlsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_generic\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                     result[name] = self._try_cast(func(data, *args, **kwargs),\n\u001b[0m\u001b[1;32m    228\u001b[0m                                                   data)\n",
      "\u001b[0;32m<ipython-input-279-574c424dcd1e>\u001b[0m in \u001b[0;36mdecodeFlatten\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mjsonlsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonlsts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4374\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4375\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_fast\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    609\u001b[0m                                           dummy)\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.SeriesGrouper.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.SeriesGrouper.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_builtin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-574c424dcd1e>\u001b[0m in \u001b[0;36mdecodeFlatten\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecodeFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mjsonlsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_pure_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_builtin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-574c424dcd1e>\u001b[0m in \u001b[0;36mdecodeFlatten\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecodeFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mjsonlsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-280-6509af3db9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgroupedDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweetsDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmaxTweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitter_account'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecodeFlatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgroupedDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aggregate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                         name=self._selected_obj.columns.name)\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_generic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_generic\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                                                   data)\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_item_by_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_item_by_item\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m                                      grouper=self.grouper)\n\u001b[1;32m    258\u001b[0m                 result[item] = self._try_cast(\n\u001b[0;32m--> 259\u001b[0;31m                     colg.aggregate(func, *args, **kwargs), data)\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mcannot_agg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func_or_funcs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_named\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_aggregate_named\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must produce aggregated value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-574c424dcd1e>\u001b[0m in \u001b[0;36mdecodeFlatten\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgressTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2065\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecodeFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mjsonlsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreppedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonlsts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/PolySpeech/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5061\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "groupedDF = tweetsDF[:maxTweets].groupby('twitter_account').aggregate(decodeFlatten).reset_index()\n",
    "groupedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"morning\", \"look\"]'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupedDF.preppedTweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF.to_csv(\"data/tweetsDFMinReadableLDApreprocessedGrouped.csv\", index=False)\n",
    "groupedDF = pd.read_csv(\"data/tweetsDFMinReadableLDApreprocessedGrouped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done preprocessing ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up log to terminal, per https://miningthedetails.com/blog/python/lda/GensimLDA/\n",
    "import logging\n",
    "logging.basicConfig(filename='lda_model.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF = pd.read_csv(\"data/tweetsDFMinReadableLDApreprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF = pd.read_csv(\"data/tweetsDFMinReadableLDApreprocessedGrouped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_account</th>\n",
       "      <th>preppedTweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1globalneighbor</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1victorgomez</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4budcook</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73eldridge</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7BOOMERESIASON</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92ndKSHouseDist</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABrindisiNY</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AC2016RNC</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD26Mathis</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADonovanCDFI</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AM4WRB2016</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AZanswers</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdamEbbin</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AdamPosen</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Al_Baldasaro</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alaskans4Hughes</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AlexDistrict52</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AlvinTownley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AnandWrites</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AndreaGiesecke</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AnneGobi</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AnthonyDaniels</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AraJNajarian</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ArmandomedinaS</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ArminMizaniTX</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AskinFrank</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AsmHarper</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Asma_Jahangir</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AspenArjun</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AttyBartley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>waltertmosley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>wandaforala2019</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>ward2bev</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>warrengraeff</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>wasserman_p</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>wences</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>wendyfranzen</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>wendygooditis</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>wenschmidt</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>wgregrothman</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>willarhh</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>willhaynie</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>wilschroder</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>winniebrinksmi</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>wittenberg4rep</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>wjm227</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>wmrodgersiii</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>wping</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>wyomingwinters</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>yessamjc</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>yianchen24</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>yokabrandt</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>ypmamigo</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>yrmcsafety</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>ysimpsonpower</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>yuhline</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>yujin_1</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>zachlaub</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>zhicks</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>zohradawood</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      twitter_account                                      preppedTweets\n",
       "0     1globalneighbor  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "1        1victorgomez  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2            4budcook  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "3          73eldridge  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "4      7BOOMERESIASON  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "5     92ndKSHouseDist  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "6         ABrindisiNY  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "7           AC2016RNC  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "8          AD26Mathis  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "9        ADonovanCDFI  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "10         AM4WRB2016  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "11          AZanswers  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "12          AdamEbbin  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "13          AdamPosen  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "14       Al_Baldasaro  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "15    Alaskans4Hughes  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "16     AlexDistrict52  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "17       AlvinTownley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "18        AnandWrites  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "19     AndreaGiesecke  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "20           AnneGobi  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "21     AnthonyDaniels  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "22       AraJNajarian  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "23     ArmandomedinaS  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "24      ArminMizaniTX  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "25         AskinFrank  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "26          AsmHarper  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "27      Asma_Jahangir  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "28         AspenArjun  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "29        AttyBartley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "...               ...                                                ...\n",
       "2035    waltertmosley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2036  wandaforala2019  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2037         ward2bev  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2038     warrengraeff  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2039      wasserman_p  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2040           wences  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2041     wendyfranzen  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2042    wendygooditis  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2043       wenschmidt  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2044     wgregrothman  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2045         willarhh  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2046       willhaynie  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2047      wilschroder  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2048   winniebrinksmi  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2049   wittenberg4rep  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2050           wjm227  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2051     wmrodgersiii  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2052            wping  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2053   wyomingwinters  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2054         yessamjc  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2055       yianchen24  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2056       yokabrandt  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2057         ypmamigo  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2058       yrmcsafety  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2059    ysimpsonpower  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2060          yuhline  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2061          yujin_1  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2062         zachlaub  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2063           zhicks  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2064      zohradawood  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "\n",
       "[2065 rows x 2 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hi1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-f0f759cb9c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hi1'"
     ]
    }
   ],
   "source": [
    "open(\"hi1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _pickle.load(file, *, fix_imports=True, encoding='ASCII', errors='strict')>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SaveLoad.load of <class 'gensim.corpora.dictionary.Dictionary'>>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.Dictionary.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/tweetsDFMinReadableLDApreprocessed.csv'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDATwitterModel(object):\n",
    "    def __init__(self, tweetsDF=None, docNum=None, NUM_TOPICS=5, grouped=False, passes=15):\n",
    "        \"\"\" tweetsDF should have a preppedTweets field \"\"\"\n",
    "        \n",
    "        helperPrefix = \"LDAHelpers/\"\n",
    "        helperSuffix = f\".docNum={docNum}.grouped={grouped}\"\n",
    "        self.modelPrefix = \"LDAModels/\"\n",
    "        self.modelSuffix = helperSuffix + f\".NUM_TOPICS={NUM_TOPICS}.gensim\"\n",
    "        self.modelPath = self.modelPrefix + \"model\" + self.modelSuffix\n",
    "        \n",
    "        # Params\n",
    "        self.NUM_TOPICS = NUM_TOPICS\n",
    "        self.passes = passes\n",
    "        \n",
    "        # Get documents\n",
    "        sys.stdout.write(\"Getting Documents...\")\n",
    "        if tweetsDF is None:\n",
    "            Grouped = \"Grouped\"\n",
    "            empty = \"\"\n",
    "            dfPath = f\"data/tweetsDFMinReadableLDApreprocessed{Grouped if grouped else empty}.csv\"\n",
    "            sys.stdout.write(f\"path {dfPath}...\")\n",
    "            self.tweetsDF = pd.read_csv(dfPath)\n",
    "        else:\n",
    "            self.tweetsDF = tweetsDF\n",
    "        sys.stdout.write(\"DF loaded...\")\n",
    "        self.text_data = [json.loads(arr) for arr in self.tweetsDF.loc[:docNum,\"preppedTweets\"]]\n",
    "        print(\"Done.\")\n",
    "\n",
    "        sys.stdout.write(\"Getting Dictionary...\")\n",
    "        try:\n",
    "            dictPath = helperPrefix + \"dictionary\" + helperSuffix + \".gensim\"\n",
    "            self.dictionary = corpora.Dictionary.load(dictPath)\n",
    "            print(f\"Reloaded from {dictPath}\")\n",
    "        except FileNotFoundError:\n",
    "            self.dictionary = corpora.Dictionary(self.text_data)\n",
    "            self.dictionary.save(dictPath)\n",
    "        print(\"Done.\")\n",
    "        \n",
    "        sys.stdout.write(\"Getting Corpus...\")\n",
    "        try:\n",
    "            corpPath = helperPrefix + \"corpus\" + helperSuffix + \".pkl\"\n",
    "            self.corpus = pickle.load(open(corpPath, \"rb\"))\n",
    "            print(f\"Reloaded from {corpPath}\")\n",
    "        except FileNotFoundError:\n",
    "            self.corpus = [self.dictionary.doc2bow(text) for text in self.text_data]\n",
    "            pickle.dump(corpus, open(corpPath, 'wb'))\n",
    "        print(\"Done.\")\n",
    "        \n",
    "    def train(self):\n",
    "        try:\n",
    "            self.ldamodel = gensim.models.ldamodel.LdaModel.load(self.modelPath)\n",
    "            print(f\"Found pretrained model {self.modelPath}\")\n",
    "            return\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        self.ldamodel = gensim.models.ldamodel.LdaModel(self.corpus, num_topics = self.NUM_TOPICS, id2word=self.dictionary, passes=self.passes)\n",
    "        self.ldamodel.save(self.modelPath)\n",
    "\n",
    "#         lda_display = pyLDAvis.gensim.prepare(self.ldamodel, self.corpus, self.dictionary, sort_topics=False)\n",
    "#         pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Documents...DF loaded...Done.\n",
      "Getting Dictionary...Done.\n",
      "Getting Corpus...Done.\n"
     ]
    }
   ],
   "source": [
    "model = LDATwitterModel(tweetsDF=groupedDF, docNum=None, grouped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = model.ldamodel.print_topics(num_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.167*\"morning\" + 0.167*\"SCREEN_NAME\" + 0.167*\"house\" + 0.167*\"white\"'),\n",
       " (1, '0.167*\"morning\" + 0.167*\"SCREEN_NAME\" + 0.167*\"house\" + 0.167*\"white\"'),\n",
       " (2, '0.167*\"morning\" + 0.167*\"SCREEN_NAME\" + 0.167*\"house\" + 0.167*\"white\"'),\n",
       " (3, '0.167*\"morning\" + 0.167*\"SCREEN_NAME\" + 0.167*\"house\" + 0.167*\"white\"'),\n",
       " (4, '0.439*\"video\" + 0.211*\"look\" + 0.139*\"white\" + 0.091*\"house\"')]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_account</th>\n",
       "      <th>preppedTweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1globalneighbor</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1victorgomez</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4budcook</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73eldridge</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7BOOMERESIASON</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92ndKSHouseDist</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABrindisiNY</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AC2016RNC</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD26Mathis</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADonovanCDFI</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AM4WRB2016</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AZanswers</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdamEbbin</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AdamPosen</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Al_Baldasaro</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alaskans4Hughes</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AlexDistrict52</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AlvinTownley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AnandWrites</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AndreaGiesecke</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AnneGobi</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AnthonyDaniels</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AraJNajarian</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ArmandomedinaS</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ArminMizaniTX</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AskinFrank</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AsmHarper</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Asma_Jahangir</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AspenArjun</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AttyBartley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>waltertmosley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>wandaforala2019</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>ward2bev</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>warrengraeff</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>wasserman_p</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>wences</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>wendyfranzen</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>wendygooditis</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>wenschmidt</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>wgregrothman</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>willarhh</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>willhaynie</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>wilschroder</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>winniebrinksmi</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>wittenberg4rep</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>wjm227</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>wmrodgersiii</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>wping</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>wyomingwinters</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>yessamjc</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>yianchen24</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>yokabrandt</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>ypmamigo</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>yrmcsafety</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>ysimpsonpower</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>yuhline</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>yujin_1</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>zachlaub</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>zhicks</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>zohradawood</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      twitter_account                                      preppedTweets\n",
       "0     1globalneighbor  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "1        1victorgomez  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2            4budcook  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "3          73eldridge  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "4      7BOOMERESIASON  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "5     92ndKSHouseDist  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "6         ABrindisiNY  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "7           AC2016RNC  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "8          AD26Mathis  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "9        ADonovanCDFI  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "10         AM4WRB2016  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "11          AZanswers  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "12          AdamEbbin  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "13          AdamPosen  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "14       Al_Baldasaro  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "15    Alaskans4Hughes  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "16     AlexDistrict52  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "17       AlvinTownley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "18        AnandWrites  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "19     AndreaGiesecke  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "20           AnneGobi  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "21     AnthonyDaniels  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "22       AraJNajarian  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "23     ArmandomedinaS  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "24      ArminMizaniTX  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "25         AskinFrank  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "26          AsmHarper  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "27      Asma_Jahangir  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "28         AspenArjun  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "29        AttyBartley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "...               ...                                                ...\n",
       "2035    waltertmosley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2036  wandaforala2019  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2037         ward2bev  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2038     warrengraeff  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2039      wasserman_p  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2040           wences  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2041     wendyfranzen  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2042    wendygooditis  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2043       wenschmidt  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2044     wgregrothman  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2045         willarhh  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2046       willhaynie  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2047      wilschroder  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2048   winniebrinksmi  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2049   wittenberg4rep  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2050           wjm227  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2051     wmrodgersiii  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2052            wping  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2053   wyomingwinters  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2054         yessamjc  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2055       yianchen24  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2056       yokabrandt  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2057         ypmamigo  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2058       yrmcsafety  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2059    ysimpsonpower  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2060          yuhline  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2061          yujin_1  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2062         zachlaub  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2063           zhicks  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2064      zohradawood  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "\n",
       "[2065 rows x 2 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tweetsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_account</th>\n",
       "      <th>preppedTweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1globalneighbor</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1victorgomez</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4budcook</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73eldridge</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7BOOMERESIASON</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92ndKSHouseDist</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABrindisiNY</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AC2016RNC</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD26Mathis</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADonovanCDFI</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AM4WRB2016</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AZanswers</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdamEbbin</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AdamPosen</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Al_Baldasaro</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alaskans4Hughes</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AlexDistrict52</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AlvinTownley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AnandWrites</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AndreaGiesecke</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AnneGobi</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AnthonyDaniels</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AraJNajarian</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ArmandomedinaS</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ArminMizaniTX</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AskinFrank</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AsmHarper</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Asma_Jahangir</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AspenArjun</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AttyBartley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>waltertmosley</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>wandaforala2019</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>ward2bev</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>warrengraeff</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>wasserman_p</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>wences</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>wendyfranzen</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>wendygooditis</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>wenschmidt</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>wgregrothman</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>willarhh</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>willhaynie</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>wilschroder</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>winniebrinksmi</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>wittenberg4rep</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>wjm227</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>wmrodgersiii</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>wping</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>wyomingwinters</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>yessamjc</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>yianchen24</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>yokabrandt</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>ypmamigo</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>yrmcsafety</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>ysimpsonpower</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>yuhline</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>yujin_1</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>zachlaub</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>zhicks</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>zohradawood</td>\n",
       "      <td>[\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      twitter_account                                      preppedTweets\n",
       "0     1globalneighbor  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "1        1victorgomez  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2            4budcook  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "3          73eldridge  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "4      7BOOMERESIASON  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "5     92ndKSHouseDist  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "6         ABrindisiNY  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "7           AC2016RNC  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "8          AD26Mathis  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "9        ADonovanCDFI  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "10         AM4WRB2016  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "11          AZanswers  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "12          AdamEbbin  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "13          AdamPosen  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "14       Al_Baldasaro  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "15    Alaskans4Hughes  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "16     AlexDistrict52  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "17       AlvinTownley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "18        AnandWrites  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "19     AndreaGiesecke  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "20           AnneGobi  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "21     AnthonyDaniels  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "22       AraJNajarian  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "23     ArmandomedinaS  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "24      ArminMizaniTX  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "25         AskinFrank  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "26          AsmHarper  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "27      Asma_Jahangir  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "28         AspenArjun  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "29        AttyBartley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "...               ...                                                ...\n",
       "2035    waltertmosley  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2036  wandaforala2019  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2037         ward2bev  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2038     warrengraeff  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2039      wasserman_p  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2040           wences  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2041     wendyfranzen  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2042    wendygooditis  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2043       wenschmidt  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2044     wgregrothman  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2045         willarhh  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2046       willhaynie  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2047      wilschroder  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2048   winniebrinksmi  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2049   wittenberg4rep  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2050           wjm227  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2051     wmrodgersiii  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2052            wping  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2053   wyomingwinters  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2054         yessamjc  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2055       yianchen24  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2056       yokabrandt  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2057         ypmamigo  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2058       yrmcsafety  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2059    ysimpsonpower  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2060          yuhline  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2061          yujin_1  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2062         zachlaub  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2063           zhicks  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "2064      zohradawood  [\"video\", \"SCREEN_NAME\", \"white\", \"house\", \"mo...\n",
       "\n",
       "[2065 rows x 2 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = preppedTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(1, 1),\n",
       "  (7, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1)]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:2] # document is tuples of word index, count. bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2460, 2)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow([\"hello\", \"hello\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open('data/corpus.pkl', 'wb'))\n",
    "dictionary.save('data/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('LDAModels/model20.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ldamodel.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel.load(\"LDAModels/model20.gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "print(ldamodel.get_document_topics(corpus[i]))\n",
    "print(text_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF.loc[i,\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for NUM_TOPICS in (5, 10):\n",
    "    print(NUM_TOPICS)\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "    ldamodel.save(f'LDAModels/model{NUM_TOPICS}.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTweets = 100000\n",
    "for doGroup in (False, True):\n",
    "    print(f'Start doGroup={doGroup}')\n",
    "    if doGroup:\n",
    "        # 500 docs by long\n",
    "        rawTweets = tweetsDF[:maxTweets*10].groupby('twitter_account')['full_text'].apply(lambda x: \"%s\" % ' --\\n '.join(x))\n",
    "    else:\n",
    "        # maxTweets docs by short\n",
    "        rawTweets = tweetsDF.loc[:maxTweets,\"full_text\"]\n",
    "\n",
    "    preppedTweets = []\n",
    "    for i, text in enumerate(rawTweets):\n",
    "        preppedTweets.append(prepare_text_for_lda(text))\n",
    "\n",
    "    text_data = preppedTweets\n",
    "    dictionary = corpora.Dictionary(text_data)\n",
    "    corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "\n",
    "    for NUM_TOPICS in (5, 10, 20):\n",
    "        if doGroup == False and NUM_TOPICS == 20:\n",
    "            break\n",
    "        print(doGroup, NUM_TOPICS)\n",
    "        ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "        ldamodel.save(f'LDAModels/model{NUM_TOPICS}.grouped={doGroup}.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTweets = 100000\n",
    "tweetsDF[:maxTweets*10].groupby('twitter_account')['full_text'].apply(lambda x: \"%s\" % ' --\\n '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel.load(\"LDAModels/model5.grouped=False.gensim\")\n",
    "i = 4\n",
    "print(ldamodel.get_document_topics(corpus[i]))\n",
    "print(text_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = LDATwitterModel(tweetsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1f3b59a9d9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = 'Practical Bayesian Optimization of Machine Learning Algorithms'\n",
    "new_doc = prepare_text_for_lda(new_doc)\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "print(new_doc_bow)\n",
    "print(ldamodel.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 3, id2word=dictionary, passes=15)\n",
    "ldamodel.save('LDAModels/model3.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 10, id2word=dictionary, passes=15)\n",
    "ldamodel.save('LDAModels/model10.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('data/corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('LDAModels/model5.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda3 = gensim.models.ldamodel.LdaModel.load('model3.gensim')\n",
    "lda_display3 = pyLDAvis.gensim.prepare(lda3, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda10 = gensim.models.ldamodel.LdaModel.load('model10.gensim')\n",
    "lda_display10 = pyLDAvis.gensim.prepare(lda10, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open(\"data/NLTKprocessedGroupedCorpus.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PolySpeech",
   "language": "python",
   "name": "polyspeech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
